{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_cmmr.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharjeelnawaz8182/standford_car_classification/blob/main/train_cmmr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__SaUl5FzXE1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import keras\n",
        "from keras.applications.resnet import ResNet50, ResNet152, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from random import randint\n",
        "from tqdm import tqdm\n",
        "import imgaug as ia\n",
        " \n",
        "img_width, img_height = 224, 224\n",
        "num_channels = 3\n",
        "train_data = '/content/drive/MyDrive/compitition/res_net/data/train'\n",
        "valid_data = '/content/drive/MyDrive/compitition/res_net/data/validation'\n",
        "num_classes = 196\n",
        "num_train_samples = 6515\n",
        "num_valid_samples = 1629\n",
        "verbose = 1\n",
        "batch_size = 16  #409 iteration, 16 batch images, at every epoch 16 images will pass and iterate back and forth 409 times updating weights\n",
        "num_epochs = 100000\n",
        "patience = 40\n",
        " \n",
        "def random_resize_crop(img, tmp_size, dst_size):\n",
        "    img = cv2.resize(img, (tmp_size, tmp_size), interpolation = cv2.INTER_CUBIC)\n",
        "    x = randint(0, tmp_size - dst_size)\n",
        "    y = randint(0, tmp_size - dst_size)\n",
        "    crop_img = img[y:y+dst_size, x:x+dst_size]\n",
        "    return crop_img\n",
        "def random_eraser(img, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255):\n",
        "    img_h, img_w, _ = img.shape\n",
        "    p_1 = np.random.rand()\n",
        "    if p_1 > p:\n",
        "        return img\n",
        "    while True:\n",
        "        s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "        r = np.random.uniform(r_1, r_2)\n",
        "        w = int(np.sqrt(s / r))\n",
        "        h = int(np.sqrt(s * r))\n",
        "        left = np.random.randint(0, img_w)\n",
        "        top = np.random.randint(0, img_h)\n",
        "        if left + w <= img_w and top + h <= img_h:\n",
        "            break\n",
        "    c = np.random.uniform(v_l, v_h)\n",
        "    img[top:top + h, left:left + w, :] = c\n",
        "    return img\n",
        "def pre_process_fun(img):\n",
        "  tmp_size=280\n",
        "  dst_size=224\n",
        "  imge=random_resize_crop(img, tmp_size, dst_size)\n",
        "  return_img=random_eraser(img=imge, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255)\n",
        "  return return_img\n",
        "model=ResNet50(include_top=True, weights=None,input_shape=(img_width, img_height,num_channels),classes=num_classes)\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()\n",
        "trained_models_path = '/content/drive/MyDrive/compitition/res_net/cp1.ckpt'\n",
        "model.load_weights(trained_models_path)\n",
        "# prepare data augmentation configuration\n",
        "train_data_gen = ImageDataGenerator(rotation_range=20,\n",
        "                                    width_shift_range=0.1,\n",
        "                                    height_shift_range=0.1,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    shear_range=0,preprocessing_function=pre_process_fun)\n",
        "valid_data_gen = ImageDataGenerator()\n",
        "# callbacks\n",
        "tensor_board = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=True) #save file log with trained data at every epoc \n",
        "log_file_path = 'logs/training.log'\n",
        "csv_logger = CSVLogger(log_file_path, append=False) #collecting training data, append-false to overide existing file \n",
        "early_stop = EarlyStopping('val_accuracy', patience=patience) #stop training if valid accuracy donot increase for 40 epochs\n",
        "reduce_lr = ReduceLROnPlateau('val_accuracy', factor=0.1, patience=int(patience / 4), verbose=1) #reducing learning rate after 10 epochs, factor to reduce learning rate\n",
        "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5' #generating weight files\n",
        "model_checkpoint = ModelCheckpoint(trained_models_path, monitor='val_accuracy', verbose=1, save_best_only=True) #save_best_only=True epoch with same name having greater accuracy will store\n",
        "callbacks = [tensor_board, model_checkpoint, csv_logger, early_stop, reduce_lr] #check accuracy,loss etc on a run to help in performing actions\n",
        "'''train_generator = MixupImageDataGenerator(generator=train_data_gen,\n",
        "                                      directory=train_data,\n",
        "                                      batch_size=batch_size,\n",
        "                                      img_height=img_height,\n",
        "                                      img_width=img_width,\n",
        "                                      subset='training')'''\n",
        "# generators\n",
        "train_generator = train_data_gen.flow_from_directory(train_data, (img_width, img_height), batch_size=batch_size,\n",
        "                                                      class_mode='categorical') #flow from directory used when we have subdirectories inside a folder, categorical-for more than two classes\n",
        "valid_generator = valid_data_gen.flow_from_directory(valid_data, (img_width, img_height), batch_size=batch_size,\n",
        "                                                      class_mode='categorical')\n",
        "\n",
        "# fine tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=407,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=num_valid_samples / batch_size,\n",
        "    epochs=num_epochs,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZUi63QPfdL1"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}